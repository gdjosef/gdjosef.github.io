import{S as Ot,i as Wt,s as Yt,B as tt,j as Lt,m as Nt,o as Ut,p as qt,q as Ct,x as zt,u as Qt,v as Jt,N as Rt,e as i,k as m,t as r,c as n,a as l,d as t,n as d,g as p,L as jt,b as h,f as s,D as o,E as Zt}from"../../chunks/vendor-30410694.js";import{L as Bt}from"../../chunks/_layout-4f1c51c6.js";function Kt(j){let u,c,v,_,f,y,E,S,ke,se,F,Te,ie,g,De,k,Ae,Pe,T,V,xe,Ge,ne,H,Ce,le,M,Re,re,w,je,D,X,Se,Fe,ee,He,Me,pe,$,$e,ue,b,Oe,A,te,We,Ye,P,oe,Le,Ne,fe,O,Ue,me,W,qe,de,Y,ze,he,I,Qe,x,ae,Je,Ze,ce,G,Ft=`<code class="language-py"><span class="token keyword">import</span> gpt_2_simple <span class="token keyword">as</span> gpt2

sess <span class="token operator">=</span> gpt2<span class="token punctuation">.</span>start_tf_sess<span class="token punctuation">(</span><span class="token punctuation">)</span>
gpt2<span class="token punctuation">.</span>load_gpt2<span class="token punctuation">(</span>sess<span class="token punctuation">)</span>

gpt2<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>sess<span class="token punctuation">,</span> run_name<span class="token operator">=</span><span class="token string">'run1'</span><span class="token punctuation">)</span></code>`,ye,L,Be,ge,C,Ht=`<code class="language-undefined">[REDACTED]: &amp;uncaption

[REDACTED]: &amp;uncaption

[REDACTED]: &amp;caption jordan

[REDACTED]: &amp;uncaption

[REDACTED]: &amp;caption

[REDACTED]: &amp;uncaption

[REDACTED]: &amp;caption

[REDACTED]: &amp;caption

[REDACTED]: &amp;uncaption

[REDACTED]: &amp;caption

[REDACTED]: &amp;caption

[REDACTED]: &amp;uncaption

[REDACTED]: &amp;caption **the</code>`,we,N,Ke,be,U,Ve,ve,q,Xe,_e,z,et,Ie,Q,R,J,ot;return{c(){u=i("p"),c=i("img"),_=m(),f=i("h1"),y=r("WHAT!?"),E=m(),S=i("p"),ke=r("Yes, ladies and gentlemen, I\u2019ve successfully stopped the habit of making blog posts relating to this site and made something of use. So without further ado, I\u2019ll get into the meat of this now."),se=m(),F=i("p"),Te=r("For this project I made, I decided to make a model for GPT-2 to create messages from the Discord server I usually talk to, \u201Cthe strip club\u201D. Truly the biggest clusterfuck of teenagers spitting out the most random shit imaginable, ever since December 10, 2020."),ie=m(),g=i("p"),De=r("My main inspiration for this project entirely lies on "),k=i("a"),Ae=r("Colon"),Pe=r("\u2019s video about "),T=i("a"),V=i("em"),xe=r("AI Generated Geometry Dash Comments"),Ge=r(", great comedic video, would rate 5/5 knee slaps \u{1F4A5}. Apart from the video, ever since I encountered OpenAI\u2019s GPT-3 API, I\u2019ve been interested in utilizing it inside one of my projects, but for this one, I instead used GPT-2. No other reason other than I couldn\u2019t be arsed to wait for the API access and the pricing for GPT-3\u2019s fine-tuning service, with GPT-2 being able to do it, well free really."),ne=m(),H=i("h1"),Ce=r("Process"),le=m(),M=i("h2"),Re=r("Getting the data (like I\u2019m Meta)"),re=m(),w=i("p"),je=r("If we\u2019re trying to fine-tune an AI, we\u2019re going to need some data. Discord doesn\u2019t give us a way to export entire channels as a big fat, probably less than 50 megabyte on this scale text file, which I\u2019d expect seeing as not many people would be doing this. Thankfully, we have a tool called "),D=i("a"),X=i("code"),Se=r("discord-scraper"),Fe=r(", a program that scrapes an "),ee=i("code"),He=r("x"),Me=r(" amount of messages using the Discord API. I did modify it slightly for my needs, removing the attachment links as this would be a purely text-only training file and modifying the format I wanted it to be in."),pe=m(),$=i("h2"),$e=r("Fine-tuning time"),ue=m(),b=i("p"),Oe=r("I\u2019ll keep this short and sweet. I don\u2019t do Python. Quite literally, my only experience is boring command line programs and self-bots. So I was going in this blind. I took an 8 hour TensorFlow course, created my own model of GPT-2 by myself. I solved world hunger using only the power of armour stands and\u2026 that didn\u2019t happen. I followed a YouTube tutorial to use and fine-tune from a text file using a module called "),A=i("a"),te=i("code"),We=r("gpt-2-simple"),Ye=r(". Listen, I wasn\u2019t going to manually do it from the "),P=i("a"),oe=i("code"),Le=r("openai/gpt-2"),Ne=r(" repo. It was going to reach this at some point and that point was this."),fe=m(),O=i("p"),Ue=r("For the actual process of fine-tuning our AI, firstly I loaded up a Jupyter notebook inside of Google Colab since I sure was hell not going to even touch/train it on my laptop. I picked a GPU for my hardware acceleration to not have to wait 5000 years for it to train. Setup some code cells such as setting the TF version, installing all the packages, mounting Google Drive and lastly, doing the function to train, making me wait an eternity (or about 1 hour and 20 minutes)."),me=m(),W=i("p"),qe=r("I probably won\u2019t be releasing the model to the public out of privacy for the people whose messages are tied to their Discord tag that are of a pretty sensitive nature. I might retrain it with the tags and other identifiable information in the content of the messages, but only time will tell if I\u2019ll ever release those versions of the model. Sorry."),de=m(),Y=i("h2"),ze=r("Text Generation"),he=m(),I=i("p"),Qe=r("After all this work. The scraping, the module downloading, some other stuff that\u2019s probably important. I arrived here. It\u2019s time to use the model. I installed "),x=i("a"),ae=i("code"),Je=r("gpt-2-simple"),Ze=r(", set it up to use my model using:"),ce=m(),G=i("pre"),ye=m(),L=i("p"),Be=r("And behold, 2 days of work and even more because of planning, returned this:"),ge=m(),C=i("pre"),we=m(),N=i("p"),Ke=r("Turns out our inability to use our bot-only channels backfired on us. And this happened a lot too with some of us and our tendency to repeat the exact same words as reactions every time returned a long list of someone saying \u201Cthis\u201D over and over again."),be=m(),U=i("h1"),Ve=r("What\u2019s Next? / Conclusion"),ve=m(),q=i("p"),Xe=r("You may be asking: \u201CWhere\u2019s the content? Did you waste 5 minutes of my precious lifetime because of this shitty AI project I made?\u201D"),_e=m(),z=i("p"),et=r("The answer is probably. When we\u2019re done working on another video reading all of our favourite ones out, you\u2019ll get to see them. So wait approximately 10 years for us to upload that video. It\u2019ll totally be worth it."),Ie=m(),Q=i("p"),R=i("a"),J=i("img"),this.h()},l(e){u=n(e,"P",{});var a=l(u);c=n(a,"IMG",{src:!0,alt:!0,title:!0}),a.forEach(t),_=d(e),f=n(e,"H1",{});var at=l(f);y=p(at,"WHAT!?"),at.forEach(t),E=d(e),S=n(e,"P",{});var st=l(S);ke=p(st,"Yes, ladies and gentlemen, I\u2019ve successfully stopped the habit of making blog posts relating to this site and made something of use. So without further ado, I\u2019ll get into the meat of this now."),st.forEach(t),se=d(e),F=n(e,"P",{});var it=l(F);Te=p(it,"For this project I made, I decided to make a model for GPT-2 to create messages from the Discord server I usually talk to, \u201Cthe strip club\u201D. Truly the biggest clusterfuck of teenagers spitting out the most random shit imaginable, ever since December 10, 2020."),it.forEach(t),ie=d(e),g=n(e,"P",{});var Z=l(g);De=p(Z,"My main inspiration for this project entirely lies on "),k=n(Z,"A",{href:!0,rel:!0});var nt=l(k);Ae=p(nt,"Colon"),nt.forEach(t),Pe=p(Z,"\u2019s video about "),T=n(Z,"A",{href:!0,rel:!0});var lt=l(T);V=n(lt,"EM",{});var rt=l(V);xe=p(rt,"AI Generated Geometry Dash Comments"),rt.forEach(t),lt.forEach(t),Ge=p(Z,", great comedic video, would rate 5/5 knee slaps \u{1F4A5}. Apart from the video, ever since I encountered OpenAI\u2019s GPT-3 API, I\u2019ve been interested in utilizing it inside one of my projects, but for this one, I instead used GPT-2. No other reason other than I couldn\u2019t be arsed to wait for the API access and the pricing for GPT-3\u2019s fine-tuning service, with GPT-2 being able to do it, well free really."),Z.forEach(t),ne=d(e),H=n(e,"H1",{});var pt=l(H);Ce=p(pt,"Process"),pt.forEach(t),le=d(e),M=n(e,"H2",{});var ut=l(M);Re=p(ut,"Getting the data (like I\u2019m Meta)"),ut.forEach(t),re=d(e),w=n(e,"P",{});var B=l(w);je=p(B,"If we\u2019re trying to fine-tune an AI, we\u2019re going to need some data. Discord doesn\u2019t give us a way to export entire channels as a big fat, probably less than 50 megabyte on this scale text file, which I\u2019d expect seeing as not many people would be doing this. Thankfully, we have a tool called "),D=n(B,"A",{href:!0,rel:!0});var ft=l(D);X=n(ft,"CODE",{});var mt=l(X);Se=p(mt,"discord-scraper"),mt.forEach(t),ft.forEach(t),Fe=p(B,", a program that scrapes an "),ee=n(B,"CODE",{});var dt=l(ee);He=p(dt,"x"),dt.forEach(t),Me=p(B," amount of messages using the Discord API. I did modify it slightly for my needs, removing the attachment links as this would be a purely text-only training file and modifying the format I wanted it to be in."),B.forEach(t),pe=d(e),$=n(e,"H2",{});var ht=l($);$e=p(ht,"Fine-tuning time"),ht.forEach(t),ue=d(e),b=n(e,"P",{});var K=l(b);Oe=p(K,"I\u2019ll keep this short and sweet. I don\u2019t do Python. Quite literally, my only experience is boring command line programs and self-bots. So I was going in this blind. I took an 8 hour TensorFlow course, created my own model of GPT-2 by myself. I solved world hunger using only the power of armour stands and\u2026 that didn\u2019t happen. I followed a YouTube tutorial to use and fine-tune from a text file using a module called "),A=n(K,"A",{href:!0,rel:!0});var ct=l(A);te=n(ct,"CODE",{});var yt=l(te);We=p(yt,"gpt-2-simple"),yt.forEach(t),ct.forEach(t),Ye=p(K,". Listen, I wasn\u2019t going to manually do it from the "),P=n(K,"A",{href:!0,rel:!0});var gt=l(P);oe=n(gt,"CODE",{});var wt=l(oe);Le=p(wt,"openai/gpt-2"),wt.forEach(t),gt.forEach(t),Ne=p(K," repo. It was going to reach this at some point and that point was this."),K.forEach(t),fe=d(e),O=n(e,"P",{});var bt=l(O);Ue=p(bt,"For the actual process of fine-tuning our AI, firstly I loaded up a Jupyter notebook inside of Google Colab since I sure was hell not going to even touch/train it on my laptop. I picked a GPU for my hardware acceleration to not have to wait 5000 years for it to train. Setup some code cells such as setting the TF version, installing all the packages, mounting Google Drive and lastly, doing the function to train, making me wait an eternity (or about 1 hour and 20 minutes)."),bt.forEach(t),me=d(e),W=n(e,"P",{});var vt=l(W);qe=p(vt,"I probably won\u2019t be releasing the model to the public out of privacy for the people whose messages are tied to their Discord tag that are of a pretty sensitive nature. I might retrain it with the tags and other identifiable information in the content of the messages, but only time will tell if I\u2019ll ever release those versions of the model. Sorry."),vt.forEach(t),de=d(e),Y=n(e,"H2",{});var _t=l(Y);ze=p(_t,"Text Generation"),_t.forEach(t),he=d(e),I=n(e,"P",{});var Ee=l(I);Qe=p(Ee,"After all this work. The scraping, the module downloading, some other stuff that\u2019s probably important. I arrived here. It\u2019s time to use the model. I installed "),x=n(Ee,"A",{href:!0,rel:!0});var It=l(x);ae=n(It,"CODE",{});var Et=l(ae);Je=p(Et,"gpt-2-simple"),Et.forEach(t),It.forEach(t),Ze=p(Ee,", set it up to use my model using:"),Ee.forEach(t),ce=d(e),G=n(e,"PRE",{class:!0});var Mt=l(G);Mt.forEach(t),ye=d(e),L=n(e,"P",{});var kt=l(L);Be=p(kt,"And behold, 2 days of work and even more because of planning, returned this:"),kt.forEach(t),ge=d(e),C=n(e,"PRE",{class:!0});var $t=l(C);$t.forEach(t),we=d(e),N=n(e,"P",{});var Tt=l(N);Ke=p(Tt,"Turns out our inability to use our bot-only channels backfired on us. And this happened a lot too with some of us and our tendency to repeat the exact same words as reactions every time returned a long list of someone saying \u201Cthis\u201D over and over again."),Tt.forEach(t),be=d(e),U=n(e,"H1",{});var Dt=l(U);Ve=p(Dt,"What\u2019s Next? / Conclusion"),Dt.forEach(t),ve=d(e),q=n(e,"P",{});var At=l(q);Xe=p(At,"You may be asking: \u201CWhere\u2019s the content? Did you waste 5 minutes of my precious lifetime because of this shitty AI project I made?\u201D"),At.forEach(t),_e=d(e),z=n(e,"P",{});var Pt=l(z);et=p(Pt,"The answer is probably. When we\u2019re done working on another video reading all of our favourite ones out, you\u2019ll get to see them. So wait approximately 10 years for us to upload that video. It\u2019ll totally be worth it."),Pt.forEach(t),Ie=d(e),Q=n(e,"P",{});var xt=l(Q);R=n(xt,"A",{href:!0,rel:!0});var Gt=l(R);J=n(Gt,"IMG",{src:!0,alt:!0}),Gt.forEach(t),xt.forEach(t),this.h()},h(){jt(c.src,v="/assets/img/exploding_computer.gif")||h(c,"src",v),h(c,"alt","Exploding computer"),h(c,"title","Google's computers begging for mercy after training"),h(k,"href","https://www.youtube.com/c/GDColon"),h(k,"rel","nofollow"),h(T,"href","https://www.youtube.com/watch?v=EpSRlZTh0U8"),h(T,"rel","nofollow"),h(D,"href","https://github.com/lnxcz/discord-scraper"),h(D,"rel","nofollow"),h(A,"href","https://github.com/minimaxir/gpt-2-simple"),h(A,"rel","nofollow"),h(P,"href","https://github.com/openai/gpt-2"),h(P,"rel","nofollow"),h(x,"href","https://github.com/minimaxir/gpt-2-simple"),h(x,"rel","nofollow"),h(G,"class","language-py"),h(C,"class","language-undefined"),jt(J.src,ot="https://img.shields.io/badge/YouTube-the%20strip%20club-red?logo=youtube")||h(J,"src",ot),h(J,"alt","YouTube channel - the strip club"),h(R,"href","https://www.youtube.com/channel/UC3oGNruOQCIP6I-yFjldw4g"),h(R,"rel","nofollow")},m(e,a){s(e,u,a),o(u,c),s(e,_,a),s(e,f,a),o(f,y),s(e,E,a),s(e,S,a),o(S,ke),s(e,se,a),s(e,F,a),o(F,Te),s(e,ie,a),s(e,g,a),o(g,De),o(g,k),o(k,Ae),o(g,Pe),o(g,T),o(T,V),o(V,xe),o(g,Ge),s(e,ne,a),s(e,H,a),o(H,Ce),s(e,le,a),s(e,M,a),o(M,Re),s(e,re,a),s(e,w,a),o(w,je),o(w,D),o(D,X),o(X,Se),o(w,Fe),o(w,ee),o(ee,He),o(w,Me),s(e,pe,a),s(e,$,a),o($,$e),s(e,ue,a),s(e,b,a),o(b,Oe),o(b,A),o(A,te),o(te,We),o(b,Ye),o(b,P),o(P,oe),o(oe,Le),o(b,Ne),s(e,fe,a),s(e,O,a),o(O,Ue),s(e,me,a),s(e,W,a),o(W,qe),s(e,de,a),s(e,Y,a),o(Y,ze),s(e,he,a),s(e,I,a),o(I,Qe),o(I,x),o(x,ae),o(ae,Je),o(I,Ze),s(e,ce,a),s(e,G,a),G.innerHTML=Ft,s(e,ye,a),s(e,L,a),o(L,Be),s(e,ge,a),s(e,C,a),C.innerHTML=Ht,s(e,we,a),s(e,N,a),o(N,Ke),s(e,be,a),s(e,U,a),o(U,Ve),s(e,ve,a),s(e,q,a),o(q,Xe),s(e,_e,a),s(e,z,a),o(z,et),s(e,Ie,a),s(e,Q,a),o(Q,R),o(R,J)},p:Zt,d(e){e&&t(u),e&&t(_),e&&t(f),e&&t(E),e&&t(S),e&&t(se),e&&t(F),e&&t(ie),e&&t(g),e&&t(ne),e&&t(H),e&&t(le),e&&t(M),e&&t(re),e&&t(w),e&&t(pe),e&&t($),e&&t(ue),e&&t(b),e&&t(fe),e&&t(O),e&&t(me),e&&t(W),e&&t(de),e&&t(Y),e&&t(he),e&&t(I),e&&t(ce),e&&t(G),e&&t(ye),e&&t(L),e&&t(ge),e&&t(C),e&&t(we),e&&t(N),e&&t(be),e&&t(U),e&&t(ve),e&&t(q),e&&t(_e),e&&t(z),e&&t(Ie),e&&t(Q)}}}function Vt(j){let u,c;const v=[j[0],St];let _={$$slots:{default:[Kt]},$$scope:{ctx:j}};for(let f=0;f<v.length;f+=1)_=tt(_,v[f]);return u=new Bt({props:_}),{c(){Lt(u.$$.fragment)},l(f){Nt(u.$$.fragment,f)},m(f,y){Ut(u,f,y),c=!0},p(f,[y]){const E=y&1?qt(v,[y&1&&Ct(f[0]),y&0&&Ct(St)]):{};y&2&&(E.$$scope={dirty:y,ctx:f}),u.$set(E)},i(f){c||(zt(u.$$.fragment,f),c=!0)},o(f){Qt(u.$$.fragment,f),c=!1},d(f){Jt(u,f)}}}const St={title:"AI Generated Strip Club Messages",date:"2021-12-22T00:00:00.000Z"};function Xt(j,u,c){return j.$$set=v=>{c(0,u=tt(tt({},u),Rt(v)))},u=Rt(u),[u]}class oo extends Ot{constructor(u){super();Wt(this,u,Xt,Vt,Yt,{})}}export{oo as default,St as metadata};
